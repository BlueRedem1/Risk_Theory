---
output: pdf_document
header-includes: 
- \usepackage{enumitem}  
- \usepackage{caption}
- \usepackage{amsmath}
- \captionsetup{labelformat=empty}
- \usepackage[utf8]{inputenc}
- \usepackage{geometry}
- \usepackage{amsmath}
- \usepackage{amssymb}
- \usepackage{tabularx}
---

```{r setup,echo=F}
knitr::opts_chunk$set(echo=T, message=FALSE, warning=FALSE, 
                      out.width='100%', fig.align='center', eval=T)
```

```{r pressure2, echo=FALSE, out.width = '240%'}
knitr::include_graphics("CARATULA.PNG")
```
\newpage

Realiza los siguientes ejercicios cuidando el formato y las reglas establecidas en la presentación del curso. Sube las soluciones a *Classroom* dentro del apartado correspondiente a esta tarea en archivos **NO COMRPIMIDOS**. 

Realiza los siguientes ejercicios entregando el desarrollo algebraico por escrito (a mano) y las conclusiones del mismo en un archivo de **R Markdown con su respectivo compilado PDF** impreso y por correo electrónico (todos los ejercicios valen lo mismo). 

# Ejercicio 1

Sea S un modelo colectivo (compuesto) con frecuencia $N\sim Bin(n,p)$ y severidad $Y\sim Ber(\theta)$. Calcula:

\begin{enumerate}[label=(\alph*)]
\item  $\mathbb{E}[S]$
\item  $Var(S)$
\item  $M_S(t)$
\item Di qué distribución tiene $S$ especificando sus parámetros.
\end{enumerate}

### Solución 
## Inciso a)

Como  \begin{align*}
\mathbb{E}[S] &= \mathbb{E}[N] \mathbb{E}[Y]\\
              &= np(\theta)\\
              &= np\theta\\
\therefore \mathbb{E}[S] &= np\theta_\blacksquare
\end{align*}

## Inciso b) 

Como  \begin{align*}
Var(S) &= Var(N) \mathbb{E}^{2}(Y) + Var(Y) \mathbb{E}(N)\\
       &= [np(1-p)]\theta^{2} + [\theta(1 - \theta)] np\\
\therefore Var(S) &= [np(1-p)]\theta^{2} + [\theta(1 - \theta)] np_\blacksquare
\end{align*}

## Inciso c)

Como  \begin{align*}
M_{S}(t) &= M_{N} (ln(M_{Y}(t)))\\
\text{Y como} \quad M_{N}(t) &= (1-p + pe^{t})^{n}\\
              M_{Y}(t) &= (1 - \theta + \theta e^{t})\\
              &\implies ln(M_{Y}(t)) = ln(1 - \theta + \theta e^{t})\\
              &\implies M_{S}(t) = (1 - p + p e^{ln(1 - \theta + \theta e^{t})})^{n}\\
              &= (1 - p + p (1 - \theta + \theta e^{t}))^{n}\\
              &= (1 \textcolor{red}{- p + p} - \theta p + \theta p e^{t})^{n}\\
              &= (1 - \theta p + \theta p e^{t})^{n}\\
\therefore M_{S}(t) &= (1 - \theta p + \theta p e^{t})^{n}_\blacksquare
\end{align*}

## Inciso d)
Notemos que $S \sim \text{Binomial compuesta} (n,p,b = Bernoulli(\theta))$

Además, de manera más especifica; $S \sim \text{Binomial}(n, \theta p) \quad \text{por su fmg.}_\blacksquare$

# Ejercicio 2

Sea S un modelo colectivo (compuesto) con frecuencia $N\sim BinNeg(r,p)$ y severidad $Y\sim Ber(\theta)$. Calcula:

\begin{enumerate}[label=(\alph*)]
\item  $\mathbb{E}[S]$
\item  $Var(S)$
\item  $M_S(t)$
\item Di qué distribución tiene $S$ especificando sus parámetros.
\end{enumerate}

### Solución
## Inciso a)

Como  \begin{align*}
\mathbb{E}[S] &= \mathbb{E}[N] \mathbb{E}[Y]\\
              &= \frac{r (1 - p)}{p}(\theta)\\
              &= r\theta \left(\frac{1}{p} - 1\right)\\
\therefore \mathbb{E}[S] &= r\theta \left(\frac{1}{p} - 1\right)_\blacksquare
\end{align*}

## Inciso b)

Como  \begin{align*}
Var(S) &= Var(N) \mathbb{E}^{2}(Y) + Var(Y) \mathbb{E}(N)\\
       &= \frac{r(1 - p)}{p^{2}}\theta^{2} + [\theta(1 - \theta)] \frac{r (1 - p)}{p}\\
\therefore Var(S) &= \frac{r(1 - p)}{p^{2}}\theta^{2} + [\theta(1 - \theta)] \frac{r (1 - p)}{p}_\blacksquare
\end{align*}

## Inciso c)

Como  \begin{align*}
M_{S}(t) &= M_{N} (ln(M_{Y}(t)))\\
\text{Y como} \quad M_{N}(t) &= \left[\frac{p}{1 - (1 - p)e^{t}}\right]^{r}\\
              M_{Y}(t) &= (1 - \theta + \theta e^{t})\\
              &\implies ln(M_{Y}(t)) = ln(1 - \theta + \theta e^{t})\\
              &\implies M_{S}(t) = \left[\frac{p}{1 - (1 - p) e^{ln(1 - \theta + \theta e^{t})}}\right]^{r}\\
              &= \left[\frac{p}{1 - (1 - p) \left[1 - \theta + \theta e^{t}\right]}\right]^{r}\\
\therefore M_{S}(t) &= \left[\frac{p}{1 - (1 - p) \left[1 - \theta + \theta e^{t}\right]}\right]^{r}_\blacksquare
\end{align*}

## Inciso d)
Sea $N \sim \text{Binomial Negativa} (r,p) \quad \text{y}\quad  Y \sim Bernoulli(\theta)$, es decir;

\begin{align*}
S &= \sum_{i = 1}^{N}Y_{i}; S|N = n \sim Bin(n,\theta)\\
\implies \mathbb{P}(S = k) &= \sum_{n = k}^{\infty} \mathbb{P}(S = K | N = n)\mathbb{P}(N = n)\\
&= \sum_{n=k}^{\infty} \binom{n}{k} \theta^{k} (1 -  \theta)^{n-k} \binom{n + r - 1}{n}(1 - P)^{r}P^{n}\\
&= (1 - P)^{r} \sum_{n = k}^{\infty} \left(\frac{\textcolor{red}{n!}}{k! (n - k)!}\right)\left(\frac{(n + r - 1)!}{\textcolor{red}{n!}(r-1)!}\right) P^{n}\textcolor{red}{\theta^{k}} \frac{(1 - \theta)^{n}}{(1 - \theta)^{k}}\\
&= \frac{(1 - P)^{r}}{k! (r - 1)!} \left(\frac{\theta}{1 - \theta}\right)^{k} \sum_{n = k}^{\infty} \frac{(n + r - 1)!}{(n - k)!}(P(1 - \theta))^{n}\\
\text{Haciendo cambio de variable,} u = n-k\\
&= \frac{(1 - P)^{r}}{(k!)(r - 1)!}\left(\frac{\theta}{1 - \theta}\right)^{k} \sum_{u = 0}^{\infty} \frac{(u + k + r - 1)!}{u!}(P(1 - \theta))^{u+k}\\
&= \frac{(1 - p)^{r}}{k!(r - 1)!}(P \theta)^{k} \sum_{u = 0}^{\infty} \underbrace{\frac{(u + k + r - 1)!}{u!}(P(1 - \theta))^{u}}_{1}\\
x = P(1 - \theta); x \in (0,1)\\
&\implies \sum_{u = 0}^{\infty} x^{u} = \frac{1}{1 - x}  \quad \underrightarrow{dx} \quad \sum_{u = 0}^{\infty} ux^{u - 1}  = \frac{1}{(1 - x)^{2}}\\
&= \sum_{u = 0}^{\infty} u x^{u - 1} = \frac{1}{(1 - x)^{2}} \quad \underrightarrow{dx} \quad \sum_{u = 1}^{\infty} u(u - 1) x^{u - 2} = \sum_{u = 2}^{\infty} u(u - 1) x^{u - 2}
\end{align*}
\begin{align*}
&= \frac{2}{(1 - x)^{3}}, \quad \text{Continuando inductivamente se llega a que:}\\
&\implies \sum_{u = K + r - 1}^{\infty} \left[\frac{u!}{(u - (k + r - 1))!}\right] X^{u + 1 - k - r} = \frac{(k + r - 1)!}{(1 - x)^{k + r}}\\
i = u - (k + r - 1)\\
&\implies \underbrace{\sum_{i = 0}^{\infty} \frac{(i + k + r -1)!}{i!} x^{i}}_{1} = \frac{(k + r - 1)!}{(1 - X)^{k + r}}\\
&\implies \sum_{u = 0}^{\infty} \frac{(u + k + r - 1)!}{u!} (P(1 - \theta))^{u} = \frac{(k + r - 1)!}{(1 - P(1 - \theta))^{k+ r}}\\
\implies \mathbb{P}(S = k) &= \frac{(1 - P)^{r}}{K! (r - 1)!}(P\theta)^{k} \frac{(K + r -1)!}{(1 - P (1 - \theta))^{k + r}}\\
&= \binom{k + r - 1}{k} \left(\frac{P\theta}{1 - P(1 - \theta)}\right) \left(\frac{1 - P}{1 - P(1 - \theta)}\right)^{r}\\
\left(\alpha = \frac{P\theta}{1 - P(1 - \theta)}\right) &= \binom{k + r -1}{k} \alpha^{k}(1 - \alpha)^{r} \quad \forall k \in \mathbb{N}\cup\{0\}\\
&\therefore S \sim \text{Binomial Negativa}(r, \alpha)_\blacksquare
\end{align*}


# Ejercicio 3

Considera los siguientes 3 riesgos de una compañía:

$$S_j\sim\text{PoiComp}\left(\lambda_j=j^2,F_{Y_j}\right)$$

Donde las severidades están dadas por:


- $F_{Y_1}(y)=1-e^{-0.5y} \mathbb{I}^{(y)}_{\{y>0\}}$
- $Y_2$ pertenece a la clase (a,b,0) con: $a=0.1$ , $b=2(0.1)$ y $p_0=(0.9)^{3}$
- $Y_3$ es la v.a. del monto de pérdida de una compañía de seguros con un **contrato de monto máximo de beneficio** $u=50$ donde el monto de pérdida del siniestro es $X\sim Exp\left(\lambda=\frac{1}{100}\right)$ ($E[X]=100$).


Define el riesgo $S$ de la compañía como:

$$S=\sum_{j=1}^{3} S_j$$

**Fija la semilla en 6**, simula $n=1,000,000$ observaciones de $S$ y calcula de manera muestral:

\begin{enumerate}[label=(\alph*)]
\item  El coeficiente de variación de $S$.
\item  Un valor $z$ tal que $F_S(500)\approx \Phi(z)$.
\end{enumerate}

### Solución 
\textcolor{red}{Observaciones:}

\begin{align*}
a &= 0.1 \epsilon (0,1)\\
b &= 2(0.1) \geq 0\\
p_{0} &= (0.9)^{3}\\
&\therefore \text{Es Binomial Negativa con p = 0.9 y r = 3}
\end{align*}

Por otro lado, \begin{align*}
F_{Y}(Y) &= 1 - e^{-0.5_{Y}} \mathbb{I}_{\{Y > 0\}}^{(y)}\\
&\therefore \text{Es Exponencial} \quad \lambda = 0.5 = \frac{1}{2}
\end{align*}

Finalmente veamos que; $Y_{3} = mín(exp(\frac{1}{100})50)$

Por otro lado, haciendo uso de Dart Vader;

\begin{align*}
& \int_{0}^{50} S(x)dx\\
&= \int_{0}^{50} e^{-\lambda x} + 50e^{-\lambda(50)} = -\frac{e^{-\lambda x}}{\lambda}|_{0}^{50}\\
&= - \left(\frac{e^{-\lambda(50)}}{\lambda} - \frac{1}{\lambda}\right) + 50 * e^{-\lambda(50)}\\
&= \frac{1}{\lambda} + e^{-\lambda(50)}(50 - \frac{1}{\lambda})
\end{align*}

\textcolor{red}{Así, a continuación el código, que da respuesta a los incisos a y b}

```{r}
library(actuar)
n <- 1000000
set.seed(6)

#Parámetro de la Poisson
lambda1 <- 1^2
lambda2 <- 2^2
lambda3 <- 3^2
lambda <- lambda1 + lambda2 + lambda3

#Binomial negativa
r=3
p=0.9
S1 <- rcompound(n = n, #Genera n
                model.freq = rpois(lambda = lambda1), #N~Poi(lambda1)
                model.sev = rnbinom(size = r,p=p)) #Y~NegBinom(r=3,p=0.9) 

#Exponencial
rate_1 <- 1/2
S2 <- rcompound(n = n, #Genera n
               model.freq = rpois(lambda = lambda2), #N~Poi(lambda2)
               model.sev = rexp(rate = rate_1)) #Y~Exp(rate) 

#Exponencial topada
rate_2<- 1/100
u=50
aux<-function(n,rate,u){ #Exponencial topada a 50
  return(pmin(rexp(n=n,rate=rate),u))
}
S3 <- rcompound(n = n, #Genera n
                model.freq = rpois(lambda = lambda3), #N~Poi(lambda3)
                model.sev = aux(rate=rate_2,u)) #Y:=min(Exp(1/100),50)
S <- S1 + S2 + S3

#Teórica
mu_nbinom=r*(1/p-1)
mu_exp=1/rate_1
mu_exp_topada=1/rate_2-exp(-rate_2*u)/rate_2;mu_exp_topada
mean(aux(5000,rate=rate_2,u))

mu<-lambda*(lambda1*mu_nbinom +  #Esperanza de la binomial negativa
        lambda2*mu_exp + #Esperanza de la exponencial
        lambda3*mu_exp_topada #Esperanza de la exponencial topada
        )/lambda ; mu
#Muestral
mu_muestral<-mean(S)

#Coinciden!

#Teorica 

#2do momento de la binomial negativa
mu_2_nbinom=(r*(1-p)/p^2+(r*(1-p)/p)^2)
#2do momento de la Exponencial
mu_2_exp=(2/rate_1^2)
#2do momento de la Exponencial topada
mu_2_exp_topada=((exp(-rate_2*u)*(-rate_2*u*(rate_2*u+2)-2)+2)/rate_2^2+(50^2)*exp(-rate_2*50))
var<-lambda*(
        lambda1*mu_2_nbinom + 
        lambda2*mu_2_exp +
        lambda3*mu_2_exp_topada
        )/lambda;var
var_muestral<-var(S)
```
El coeficiente de variación es:
```{r}
Coeficiente_variacion<-sd(S)/abs(mean(S))
Coeficiente_variacion
```
$\blacksquare$

Un valor de z tal que $F_s(500)\approx \Phi (z)$:

```{r}
z<-(500-mean(S))/sd(S)
z
pnorm(z)
quantile(S,pnorm(z))
```
$\blacksquare$

# Ejercicio 4

El monto agregado de $S$ de un riesgo tiene distribución binomial compuesta $N\sim Bin(n=10,p=0.4)$ donde los montos de reclamación tienen una función de masa de probabilidad:

$$ 
f_X(x)=\mathbb{P}[X=x]
\begin{cases}
0.40 \quad, \hspace{0.8cm} \text{si} \hspace{0.4cm} x = 1\\
0.35  \quad, \hspace{0.8cm} \text{si} \hspace{0.4cm} x=2\\
0.25  \quad, \hspace{0.8cm} \text{si} \hspace{0.4cm} x=3
\end{cases}
$$

\begin{enumerate}[label=(\alph*)]
\item Calcula $\mathbb{P}[S\leq 5]$
\item Calcula $\mathbb{P}[S = 6]$
\end{enumerate}

# Ejercicio 5

Sea $S$ un modelo colectivo compuesto con $N\sim Poi(1)$ y $Y_i\sim Exp(1) \hspace{0.25cm} \forall i\in \{1,2,\dots\}$. Escriba la fórmula para la aproximación de $F_S(x)$ según el método de gamma trasladada.

### Solución

Veamos lo siguiente:

$$ N \sim Poi(1); \quad Y_{i} \sim Exp(1); \quad \mathbb{E}\frac{[(S - \mathbb{E}[S])^{3}]}{\sqrt{Var^{3}(S)}} $$


\begin{align*}
\binom{n}{k} &= \frac{n!}{(n - k)k!}\\
\binom{3}{0} &= 1\\
\binom{3}{1} &= \frac{3!}{2!1!} = 3\\
\binom{3}{2} &= \frac{3!}{1!2!} = 3\\
\binom{3}{3} &= 1
\end{align*}
\begin{align*}
& \mathbb{E}[S^{3} - 3S^{2}\mathbb{E}[S] + 3S\mathbb{E}^{2}[S] - \mathbb{E}^{3}[S]]\\
&= \mathbb{E}[S^{3}] - 3 \mathbb{E}[S]\mathbb{E}[S^{2}] + 3 \mathbb{E}[S]\mathbb{E}^{2}[S] - \mathbb{E}^{3}[S]\\
&= \mathbb{E}[S^{3}] - 3 \mathbb{E}[S]\mathbb{E}[S^{2}] + 2 \mathbb{E}^{3}[S]
\end{align*}
Ahora;
\begin{align*}
M_{S}(t) &= e^{\lambda(M_{Y}(t) - 1)}; N \sim Poi(1) \implies M_{S}(t) = e^{(M_{Y}(t) - 1)}\\
\text{Pero} Y_{i} \sim Exp(1) &\implies M_{Y}(t) = \frac{\lambda}{\lambda - t} = \frac{1}{1 - t}\\
\implies M_{S}(t) =& e^{\left[\frac{1}{1 - t} - 1\right]} = e^{\frac{1}{1 - t} - \frac{1 - t}{1 - t}} = e^{\frac{\textcolor{red}{1-1} + t}{1 - t}} = e^{\frac{t}{1 - t}}\\
\implies M_{S}(t) &= \frac{t}{1 - t}\\
\implies M'_{S}(t) &= e^{\frac{t}{1 - t}}\left[\frac{(1 \textcolor{red}{- t) + t}}{(1 - t)^{2}}\right]\\
&= e^{\frac{t}{1 - t}}\left[\frac{1}{(1 - t)^{2}}\right]\\
M'_{S}(t) &= e^{\frac{t}{1 - t}}(1 - t)^{-2}\\
\implies M'_{S}(0) &= 1 = \mathbb{E}[S]\\
\implies M''_{S}(t) &= e^{\frac{t}{1 - t}}(1 - t)^{-4} + e^{\frac{t}{1 - t}}[-2(-1)(1 - t)^{-3}]\\
&= e^{\frac{t}{1 - t}}(1 - t)^{-4} + 2e^{\frac{t}{1 - t}}(1 - t)^{3}\\
\implies M''_{S}(0) &= 1 + 2(1) = 3 = \mathbb{E}[S^{2}]\\
\implies M'''_{S}(t) &= e^{\frac{t}{1 - t}} (1 - t)^{-t} + e^{\frac{t}{1 - t}}[-6(-1)(1 - t)^{-5}] + 2 \left[e^{\frac{t}{1 - t}}(1 - t)^{-5} + e^{\frac{t}{1 - t}}[-3(-1)(1 - t)^{-4}]\right]\\
&= e^{\frac{t}{1 - t}} \left[(1 - t)^{-6} + 6(1 - t)^{-5} + 2(1 - t)^{-5} + 6(1 - t)^{-4}\right]\\
&= e^{\frac{t}{1 - t}} \left[(1 - t)^{-6} + 8(1 - t)^{-5} + 6(1 - t)^{-4}\right]\\
\implies M'''_{S}(t) &= 1[1 + 8 + 6]\\
&= 15 = \mathbb{E}[S^{3}]\\
\therefore \mathbb{E}[S]= 1 &; \mathbb{E}[S^{2}] = 3; \mathbb{E}[S^{3}] = 15\\
\implies Var(S) = 3 - 1^{2} &= 3 - 1 = 2 \implies \sqrt{Var^{3}} = \sqrt{2^{3}} = \sqrt{8}\\
\implies \mathbb{E}[S - \mathbb{E}[S]]^{3} &= 15 - 3(1)(3) + 2(1)^{3}\\
&= 15 - 9 +2\\
&= 8\\
\end{align*}
\begin{align*}
\implies \mathbb{E}[S] &=  M = 1\\
\implies Var(S) &= \sigma^{2} = 2\\
\implies \frac{\mathbb{E}[(S - \mathbb{E}[S])^{3}]}{\sqrt{Var^{3}(S)}} &= \frac{8}{\sqrt{8}} = \underbrace{\sqrt{8}}_{\text{Coeficiente de asimetría}} = \alpha
\end{align*}
\begin{align*}
\text{Luego;} \quad C &= M - \frac{2\sigma}{\alpha} = 1 - \frac{2\sqrt{2}}{\sqrt{8}} = 1 - \frac{2\sqrt{2}}{2\sqrt{2}} = 1 - 1 = 0\\
\beta &= \frac{4}{\alpha^{2}} = \frac{4}{8} = \frac{1}{2}\\
\lambda &= \frac{2}{\sigma \alpha} = \frac{2}{\sqrt{2}\sqrt{8}} = \frac{2}{\sqrt{2}\sqrt{2^{3}}} =  \frac{2}{\sqrt{2^{4}}} = \frac{2}{4} = \frac{1}{2}\\
\implies F_{S}(t) &\sim \mathbb{P}[Z \leq t - m + \frac{2\sigma}{\alpha}]\\
&= F_{Z}(t - \underbrace{m + \frac{2\sigma}{\alpha}}_{-C \quad \text{Ya que} \quad C = M - \frac{2\sigma}{\alpha}})\\
&= F_{Z}(t - C)
\end{align*}

Donde, $Z \sim Gamma(\beta = \frac{1}{2}, \lambda = \frac{1}{2})$ y como $C = 0 \implies F_{Z}(t - C) = F_{Z}(t) = \mathbb{P} [Z \leq t]$

```{r}
pgamma(3,1/2,1/2) # con gamma trasladada
aux<-rcompound(n = n, #Genera n
                model.freq = rpois(lambda = 1), #N~Poi(lambda1)
                model.sev = rexp(1)) #Y~NegBinom(r=3,p=0.9)
sum(aux<=3)/n #con simulación
```

$\blacksquare$

# Ejercicio 6

Considera el siguiente riesgo de una compañía:

$$S=\sum_{i=1}^{N^*} Y_i$$

Se sabe que la severidad $Y$ está sujeta a un deducible $d=2$ y un monto máximo de beneficio $u=4$, los cuales buscan cubrir un monto de siniestro $X$ tiene una función de masa de probabilidad:

\vspace{-0.5cm}

\begin{center}
\captionof{table}{}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
$k$ & 1 & 2 & 3 & 4 & 5   \\  \hline 
\rule[-1.5ex]{0pt}{4ex}$\mathbb{P}\left[X=k\right]$  & $\frac{7}{18}$ & $\frac{5}{18}$ & $\frac{3}{18}$ & $\frac{2}{18}$ & $\frac{1}{18}$ \\  \hline
\end{tabular}
\end{center}

Además, se sabe que hay 4 pólizas (clientes) en el portafolio y que para siniestros de este estilo reclaman 20 de cada 100 **clientes normales**. Sin embargo, **los 4 clientes de este portafolio son especiales**, pues hay una probabilidad del 70\% de que **ninguno sufra un siniestro**. Se ha acordado respetar la distribución de la frecuencia para clientes normales únicamente **modificando** la probabilidad de que ninguno sufra un siniestro para este portafolio.

**Fija la semilla en 93**, genera $n=1,000,000$ simulaciones de la variable aleatoria $S$, y de esta muestra obtén:

\begin{enumerate}[label=(\alph*)]
\item Media,
\item Segundo momento,
\item Varianza,
\item Coeficiente de variación.
\end{enumerate}

De manera muestral (aproximada).

Hints:

- ¿Qué distribución tiene la frecuencia de los clientes normales si hay un portafolio con 4 pólizas? ($N$)

- Con base en $N$, ¿cómo es la distribución de los clientes especiales en el portafolio? ($N^*$)

- *Coeficiente de variación* $:= \frac{\sigma}{\mu} = \frac{\sqrt{Var(S)}}{\mathbb{E}[S]}$

# Ejercicio 7

Del mismo riesgo ($S$) del ejercicio 6 obtén:

\begin{enumerate}[label=(\alph*)]
\item Media,
\item Segundo momento,
\item Varianza,
\item Coeficiente de variación.
\end{enumerate}

De manera teórica (exacta) utilizando las propiedades del modelo colectivo.

*Sugerencia: compara con el ejercicio 6.*

# Ejercicio 8

Del ejercicio 6, obtén el soporte de la variable aleatoria del riesgo de la compañía ($S$), justifica porqué ese es el soporte dando **solo un ejemplo** del porqué es un valor factible para $S$ con un vector del estilo:

$$(N^*=n,Y_1=y_1,Y_2=y_2,\dots,Y_n=y_n) \Rightarrow S = x$$

por cada valor $x$ en el soporte de $S$ (esto sirve para exhibir que existe probabilidad positiva de que el riesgo de la compañía valga dicho valor puntual $x$). Crea la función de Panjer para calcular la función de densidad (masa de probabilidad) de $S$. **Muestra el código de la función que acabas de crear** especificando qué es cada parámetro de la función (si los recibe).

# Ejercicio 9

Una vez identificado el soporte y teniendo implementada la función de Panjer en el ejercicio 8, calcula:

\vspace{-0.3cm}

$$
\mathbb{P}[S=x] \hspace{0.2cm} \forall x\in sop\{S\}
$$

\vspace{-0.3cm}

y con esos valores:

\begin{enumerate}[label=(\alph*)]
\item Verifica que suman uno las probabilidades.
\item Obtén la media.
\item Obtén el $VaR_{0.90}^{(S)}$.
\item Obtén la moda.
\end{enumerate}

*Sugerencia: para que tú mismo compruebes que lo que estás haciendo está bien, con esta función de densidad que acabas de crear estaría bien que calcularas todo lo del ejercicio 8. Será rápido si ya tienes que suman uno las probabilidades.*

# Ejercicio 10

Utiliza los datos simulados y las probabilidades puntuales teóricas de los ejercicios 6 y 9 para realizar una prueba estadística que pruebe las siguientes hipótesis nulas:

\begin{enumerate}[label=(\alph*)]
\item $H_0:$  La proporción de observaciones de las categorías "igual a la moda" y "diferente de la moda" concuerda con las probabilidades teóricas.
\item $H_0:$  La proporción de observaciones de las categorías "menor o igual al $VaR_{0.90}^{(S)}$" y "mayor estricto al $VaR_{0.90}^{(S)}$" concuerda las probabilidades teóricas.
\end{enumerate}

**Para cada prueba muestra los observados, los esperados, interpreta claramente el p-value y concluye.**


